# LLM-daily-learning

## 大模型学习与分享

> “凡学之不勤，必其志之尚未笃也。”  
> ——这是我始终坚信的一句话。学习之所以不够努力，是因为心还不够坚定。

我开始这个项目，是为了记录自己在大语言模型（LLM）领域的学习旅程，也希望能借此和更多志同道合的朋友一起交流、成长。

我会持续更新我在以下几个方向的学习内容：

- 基础知识：Transformer、Attention、Tokenizer、模型架构等
- Prompt 工程：Zero-shot、Few-shot、Chain-of-Thought 等技巧
- 微调方法：LoRA、Adapter、SFT、RLHF 等实战经验
- 部署优化：本地部署、量化、推理加速等实用内容

目前只完成了「微调方法」部分的内容整理，后续会逐步完善其他模块。

---

### 📁 当前目录结构

```
.
└── 微调方法/
    ├── LoRA系列微调方法.md
    └── ...（陆续更新）
```

---

### 🌱 未来计划

我希望这个仓库不仅能成为自己的知识库，也能成为一个开放、共享、可协作的学习社区。如果你也在学习大模型，欢迎关注、Star 或者一起讨论！

---

### 💬 欢迎交流

如果你对某个知识点感兴趣，或者想一起探讨某个问题，欢迎留言或提 PR。  
我们一起进步，一起变得更强！

---

### ⭐ 如果你喜欢这个项目，请点个 Star 支持一下 👇  
