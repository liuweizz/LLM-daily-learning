
# LLM-daily-learning  

> “凡学之不勤，必其志之尚未笃也。”  
> —— 学习之所以不够努力，是因为心还不够坚定。

我开始这个项目，是为了记录自己在大语言模型（LLM）领域的学习旅程。从基础知识到实战应用，我希望通过不断总结和分享，让自己走得更远，也希望遇到更多志同道合的朋友一起交流、成长。

目前，我已经完成了部分模块的内容整理，但还有很多地方需要完善。如果你也在学习大模型，欢迎关注Star 或者一起讨论！

---

## 📚 当前目录结构

### 大模型基础架构
- **BERT**
- **Transformer 模型**
- **常见大模型**
- **注意力机制**
- **解码部分**

### 大模型微调方法
- **Llama-factory 使用方法.pdf**
- **LoRA 系列微调方法.md**

### 大模型模型基础
- **Transformer 和 Bert.pdf**
- **jieba 分词用法.pdf**
- **分词与词向量.pdf**
- **语言模型.pdf**

---

## 🌱 未来计划

我希望这个仓库不仅能成为自己的知识库，也能成为一个开放、共享、可协作的学习社区。目前还在逐步完善中，以下是一些未来的方向：

- **Prompt 工程**：Zero-shot、Few-shot、Chain-of-Thought 等技巧。
- **部署优化**：本地部署、量化、推理加速等实用内容。
- **案例实践**：结合实际项目，分享微调和部署的经验。

如果你对某个模块感兴趣，或者想提前看到某些内容，欢迎留言或提 PR，我们一起推动这个项目的成长！

---

## 💬 欢迎交流

如果你对某个知识点感兴趣，或者想一起探讨某个问题，欢迎留言或提 PR。  
无论是技术细节还是学习心得，都可以聊聊！我们一起进步，一起变得更强。

---

## 🌟 结束语

> “哪怕真理无穷，追求的脚步也不会停止。”

学习是一个永无止境的过程，而分享则是让这条路变得更有趣的方式。希望这个项目能陪伴你我共同成长，期待与你相遇在知识的光里。

—— by [WeiZhong_Liu] 🌟

---
